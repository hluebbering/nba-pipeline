# NBA Insight Engine

> Build a reusable pipeline that ingests multiâ€‘modal NBA data, transforms it in BigQuery, and serves advanced models & dashboards that explain storylines (e.g., Pacersâ€™ Gameâ€¯7 push) and project future performance (e.g., Timberwolves 2025 season outlook).



- [Core Questions](#core-questions)
- [Objectives](#objectives)
- [Architecture](#architecture)
- [Data Sources](#data-sources)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Setup](#setup)
- [Quickstart](#quickstart)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)




---


## Core Questions

1. **Player performance forecasting** â€“ How many points, USG%, TS%, etc. will a player post next game?
2. **Team over/underâ€‘performance** â€“ Which clubs are beatingâ€”or falling short ofâ€”their underlying metrics and why?
3. **Narrative validation** â€“ Are fatigue, lineup tweaks, or media sentiment driving momentum swings?
4. **Season simulations** â€“ What are team win totals & playoff odds under Monteâ€‘Carlo runs?

## Objectives

- ğŸ€ **Player Models**Â â€“ CatBoost/JAXâ€‘Boost nextâ€‘game projections.
- ğŸ”® **Team Sims**Â â€“ ELO + Gradientâ€‘Boost matchup engine.
- ğŸ“Š **Storyline Analytics**Â â€“ Quantify fatigue, sentiment, clutch streaks.
- â± **Flexible Scheduling**Â â€“ Daily inâ€‘season, weekly offâ€‘season, onâ€‘demand triggers.

## Architecture

<details>

```mermaid
flowchart TD
  A[Dagster Assets] -->|APIs & Scrapers| B(GCS Raw)
  B --> C(BigQuery Bison: raw -> core -> marts)
  C --> D(dbt 1.9 + Mesh)
  D --> E(Feast Feature Store)
  E --> F[CatBoost GPU / JAXâ€‘Boost]
  D --> G(Streamlit 2.0 Dashboards)
  C --> H(FastAPI + Arrow Flight SQL)
```

</details>




### Pipeline Steps

1. **Ingest**Â â€“ Dagster + Fugue parallel pulls from `nba_api`, ESPN Inactives, Second Spectrum, Twitter v2, GDELT.
2. **Stage**Â â€“ Versioned Parquet in GCS; DuckDB Cloud Cache for local dev.
3. **Warehouse**Â â€“ Partitioned/clustered BigQuery (Bison release).
4. **Transform**Â â€“ dbt tests, docs, macros; feature marts.
5. **Feature Store**Â â€“ Feast on BigQuery.
6. **Model**Â â€“ MLflowÂ 3.0 experiments; scheduled retrain.
7. **Serve**Â â€“ StreamlitÂ 2.0 dashboards + REST/gRPC endpoints.
8. **CI/CD**Â â€“ GitHub Actions, Dagster Deployments, dbt Cloud jobs.

## Data Sources

| Domain             | Example Fields              | Primary Source           |
| ------------------ | --------------------------- | ------------------------ |
| Box/Playâ€‘byâ€‘play   | points, fouls, possessions  | `nba_api` bulk endpoints |
| Advanced Metrics   | ORTG, TS%, PACE             | Basketballâ€‘Reference     |
| Injuries & Lineups | player status, DNPs         | ESPN scraper             |
| Player Tracking    | shot distance, speed        | Second Spectrum          |
| Social Sentiment   | tweets per player, polarity | Twitter APIÂ v2           |
| News Tone          | headline sentiment          | GDELT RSS                |

## Tech Stack

| Layer               | Tooling                                           |
| ------------------- | ------------------------------------------------- |
| Language            | PythonÂ 3.11 (pandas, **polars**, RAPIDS cuDF)     |
| Ingestion           | DagsterÂ 1.6, Fugue, Ray                           |
| Storage             | GCS, BigQuery **Bison**                           |
| Transform           | dbtÂ 1.9 + Mesh                                    |
| Feature Store       | Feast                                             |
| Modeling            | CatBoostâ€¯GPU, LightGBMâ€¯v5, **JAXâ€‘Boost**, Prophet |
| Experiment Tracking | MLflowÂ 3.0                                        |
| Visualization       | StreamlitÂ 2.0, Looker Studio                      |
| Orchestration       | Dagster Deployments                               |
| CI/CD               | GitHub Actions, dbt Cloud                         |

## Project Structure

```text
nba-pipeline/
â”œâ”€â”€ .github/workflows/        # CI pipelines
â”œâ”€â”€ dagster/                  # Dagster asset definitions
â”œâ”€â”€ dbt/                      # dbt project (sources, models, tests)
â”œâ”€â”€ notebooks/                # EDA & storyline notebooks
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/            # API clients & scrapers
â”‚   â”œâ”€â”€ features/             # Feature engineering code
â”‚   â””â”€â”€ models/               # Training & inference
â”œâ”€â”€ streamlit_app/            # Dashboard code
â””â”€â”€ README.md
```

## Setup

```bash
# 0.  make sure bzip2 is present (usually is)
sudo apt-get update -y && sudo apt-get install -y bzip2

# 1.  fetch + unpack straight into /usr/local/bin
curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest \
| sudo tar -xvjf - -C /usr/local/bin --strip-components=1 bin/micromamba

# 2.  verify
micromamba --version

# 3.  create & activate the env
micromamba create -y -n nba-engine -f env.yml
# eval "$(micromamba shell hook --shell bash)" # add micromamba hook to this shell only
micromamba activate nba-engine
```

## Quickstart

```bash
# Run Dagster locally
pip install -e . 
pkill -f dagster || true   # stop old server
dagster dev -w workspace.yaml

# Backfill 2023â€‘24 game logs
python src/ingestion/backfill_games.py --season 2024

# Build dbt models
dbt build --select tag:core
```

## Roadmap

| Phase | Target Date | Milestone                                   |
| ----- | ----------- | ------------------------------------------- |
| P0    | **Dayâ€¯3**   | Repo scaffold + raw games in BigQuery       |
| P1    | **Weekâ€¯2**  | dbt staging & marts for boxscore + injuries |
| P2    | **Weekâ€¯4**  | MVP CatBoost player model (RMSE benchmark)  |
| P3    | **Monthâ€¯2** | Team simulation & sentiment integration     |
| P4    | **Monthâ€¯3** | Streamlit dashboards + automated scheduling |



- Week 0 â€“ Stand up GCP project, BQ datasets, and Composer; commit repo skeleton.
- Week 1 â€“ Ingest/backfill game logs 2014-2025; populate dim_*, fct_boxscore.
- Week 2 â€“ Build dbt models for rolling player stats + team ELO; validate with Looker.
- Week 3 â€“ Baseline CatBoost model: predict next-game points (features = last-10 rolling stats, minutes, opponent DRTG, rest days).
- Week 4 â€“ Case study: Pacers-OKC series. Join fatigue (games in 14 days), social sentiment, and Net Rating trend; write blog-style notebook.


--------------------------------------


export SCRAPERAPI_KEY="xxxxxxx"
echo 'export GOOGLE_APPLICATION_CREDENTIALS=/workspaces/.gcp/key.json' >> ~/.bashrc


--------------------------------------


curl -i \
  -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36" \
  -H "Referer: https://stats.nba.com" \
  -H "Origin: https://www.nba.com" \
  -H "x-nba-stats-token: true" \
  -H "x-nba-stats-origin: stats" \
  "https://api.scraperapi.com?api_key=$KEY&premium=true&keep_headers=true&country_code=eu&retry=3&timeout=90000&url=https%3A%2F%2Fstats.nba.com%2Fstats%2Fleaguegamelog%3FCounter%3D0%26Direction%3DASC%26LeagueID%3D00%26PlayerOrTeam%3DT%26Season%3D2024-25%26SeasonType%3DRegular%2BSeason%26Sorter%3DDATE"



python - <<'PY'
from nba_engine.patch_http import nba_get
rows = nba_get(
    "leaguegamelog",
    {
        "Counter": 0, "Direction": "ASC",
        "LeagueID": "00", "PlayerOrTeam": "T",
        "Season": "2024-25", "SeasonType": "Regular Season",
        "Sorter": "DATE",
    },
)["resultSets"][0]["rowSet"]
print("leaguegamelog rows â†’", len(rows))
PY


python - <<'PY'
from nba_engine.assets.leaguegamelog_2025 import leaguegamelog_2025
print("rows:", leaguegamelog_2025().metadata["rows"])
PY




## Contributing

PRs welcome! See `CONTRIBUTING.md` for guidelines & DCO.

## License

MIT Â© 2025 Hannah L.

---


